\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[submission]{aaai2026}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{pifont} %182/183/184
\usepackage{subcaption}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{xspace}
\usepackage{amsfonts,amssymb} 
\usepackage{microtype}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
%\usepackage{subfigure}
\usepackage{times}
\usepackage{latexsym}
\usepackage{color}
\usepackage[dvipsnames, table]{xcolor}
\usepackage{soul}
\usepackage{verbatim}
\usepackage{multirow}
\usepackage{xspace}
\usepackage{amsfonts,amssymb} 
\usepackage{microtype}
%\usepackage{subfigure}
\usepackage{times}
\usepackage{latexsym}
\usepackage{color}
\usepackage[dvipsnames, table]{xcolor}
\usepackage{soul}
\usepackage{colortbl}
\usepackage{booktabs,makecell, multirow, tabularx}
\usepackage{adjustbox}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{amsmath}

\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{bbding}
\usepackage{pifont}
\usepackage{wasysym}
\usepackage{utfsym}
\usepackage{fontawesome}
\usepackage{makecell}

\usepackage{mdframed}
\begin{document}

\begin{table*}[!ht] \centering \vspace{2mm}
\caption{Evaluation results on \textsc{ProcessBench}.}\vspace{-1mm}
\scalebox{0.95}{ \begin{tabular}{lccccc} \toprule
\textbf{Model} & \textbf{GSM8K} & \textbf{MATH} & \makecell[c]{\textbf{Olympiad-} \\ \textbf{Bench}} & \makecell[c]{\textbf{Omni-} \\ \textbf{MATH}} & \textbf{Average} \\ \midrule
\multicolumn{6}{c}{\textit{Open-source \textbf{Process Reward Models (PRMs)}}} \\ \midrule
\rowcolor[rgb]{ .988,  .949,  .8} Math-Shepherd-PRM-7B & 47.9  & 29.5  & 24.8  & 23.8  & 31.5  \\
\rowcolor[rgb]{ .988,  .922,  .8} RLHFlow-PRM-Mistral-8B & 50.4  & 33.4  & 13.8  & 15.8  & 28.4  \\
\rowcolor[rgb]{ .988,  .922,  .8} RLHFlow-PRM-Deepseek-8B & 38.8  & 33.8  & 16.9  & 16.9  & 26.6  \\
\rowcolor[rgb]{ .988,  .89,  .8} Skywork-PRM-1.5B & 59.0  & 48.0  & 19.3  & 19.2  & 36.4  \\
\rowcolor[rgb]{ .988,  .89,  .8} Skywork-PRM-7B & \textbf{70.8} & 53.6  & 22.9  & 21.0  & 42.1  \\
\rowcolor[rgb]{ .922,  .89,  .988} \textbf{Qwen2.5-Math-7B-PRM800K (our trained)} & 68.2  & \textbf{62.6} & \textbf{50.7} & \textbf{44.3} & \textbf{56.5} \\ \midrule
\multicolumn{6}{c}{\textit{Open-source language models, prompted as \textbf{Critic Models}}} \\ \midrule
\rowcolor[rgb]{ .988,  .933,  .8} Meta-Llama-3-8B-Instruct & 13.1  & 13.8  & 4.8   & 12.6  & 11.1  \\
\rowcolor[rgb]{ .988,  .933,  .8} Meta-Llama-3-70B-Instruct & 52.2  & 22.8  & 21.2  & 20.0  & 29.1  \\
\rowcolor[rgb]{ .988,  .91,  .8} Llama-3.1-8B-Instruct & 10.9  & 5.1   & 2.8   & 1.6   & 5.1  \\  %%%%%
\rowcolor[rgb]{ .988,  .91,  .8} Llama-3.1-70B-Instruct & 74.9  & 48.2  & 46.7  & 41.0  & 52.7  \\
\rowcolor[rgb]{ .988,  .882,  .8} Llama-3.3-70B-Instruct & 82.9  & 59.4  & 46.7  & 43.0  & 58.0  \\
    \rowcolor[rgb]{ .882,  .949,  .89} Qwen2.5-Math-7B-Instruct & 26.8  & 25.7  & 14.2  & 12.7  & 19.9  \\
    \rowcolor[rgb]{ .882,  .949,  .89} Qwen2.5-Math-72B-Instruct & 65.8  & 52.1  & 32.5  & 31.7  & 45.5  \\
    \rowcolor[rgb]{ .882,  .933,  .933} Qwen2.5-Coder-7B-Instruct & 14.3  & 6.5   & 4.1   & 1.8   & 6.7  \\
    \rowcolor[rgb]{ .882,  .933,  .933} Qwen2.5-Coder-14B-Instruct & 50.1  & 39.9  & 34.0  & 27.3  & 37.8  \\
    \rowcolor[rgb]{ .882,  .933,  .933} Qwen2.5-Coder-32B-Instruct & 68.9  & 60.1  & 48.9  & 46.3  & 56.1  \\
    \rowcolor[rgb]{ .882,  .922,  .969} Qwen2-7B-Instruct & 8.4   & 19.0  & 14.7  & 12.1  & 13.6  \\
    \rowcolor[rgb]{ .882,  .922,  .969} Qwen2-72B-Instruct & 67.6  & 49.2  & 42.1  & 40.2  & 49.8  \\
    \rowcolor[rgb]{ .89,  .89,  .969} Qwen2.5-7B-Instruct & 36.5  & 36.6  & 29.7  & 27.4  & 32.6  \\
    \rowcolor[rgb]{ .89,  .89,  .969} Qwen2.5-14B-Instruct & 69.3  & 53.3  & 45.0  & 41.3  & 52.2  \\
    \rowcolor[rgb]{ .89,  .89,  .969} Qwen2.5-32B-Instruct & 65.6  & 53.1  & 40.0  & 38.3  & 49.3  \\
    \rowcolor[rgb]{ .89,  .89,  .969} Qwen2.5-72B-Instruct & 76.2  & 61.8  & 54.6  & 52.2  & 61.2  \\
    \rowcolor[rgb]{ .949,  .89,  .988} \boldmath{}\textbf{$\bigstar$ QwQ-32B-Preview}\unboldmath{} & \textbf{88.0} & \textbf{78.7} & \textbf{57.8} & \textbf{61.3} & \textbf{71.5} \\ \midrule
\multicolumn{6}{c}{\textit{Proprietary language \textbf{Critic Models}}} \\ \midrule
\rowcolor[rgb]{ .906,  .902,  .902} GPT-4o-0806 & 79.2  & 63.6  & 51.4  & 53.5  & 61.9  \\
    \rowcolor[rgb]{ .816,  .808,  .808} o1-mini & 93.2  & 88.9  & 87.2  & 82.4  & 87.9  \\ \bottomrule \end{tabular} } \end{table*}%


\end{document}